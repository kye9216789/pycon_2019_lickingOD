{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from src.anchor.anchor_generator import (gen_base_anchors, get_anchors, \n",
    "                              grid_anchors, meshgrid)\n",
    "from src.core.bbox.assigners import AssignResult\n",
    "from src.datasets.loader.build_loader import build_dataloader\n",
    "from src.models.builder import build_backbone, build_neck, build_head\n",
    "from mmcv.runner import obj_from_dict\n",
    "from mmcv.utils.config import Config\n",
    "from src.core import multi_apply, weighted_smoothl1, weighted_sigmoid_focal_loss\n",
    "from src.core.anchor import anchor_target_single, images_to_levels, unmap, anchor_inside_flags, expand_binary_labels\n",
    "\n",
    "from src.core.bbox import assign_and_sample, build_assigner, PseudoSampler, bbox2delta\n",
    "\n",
    "%store -r anchor_target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[ -19.,   -7.,   26.,   14.],\n",
       "          [ -25.,  -10.,   32.,   17.],\n",
       "          [ -32.,  -14.,   39.,   21.],\n",
       "          ...,\n",
       "          [1163.,  342., 1524., 1065.],\n",
       "          [1116.,  248., 1571., 1159.],\n",
       "          [1057.,  129., 1630., 1278.]])],\n",
       " [tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0', dtype=torch.uint8)],\n",
       " [tensor([[ 748.0838,  304.4447,  980.2133,  747.1882],\n",
       "          [ 707.9063,   46.1551, 1026.3268,  670.4366],\n",
       "          [ 982.3378,  359.9517, 1055.0696,  458.0521],\n",
       "          [1012.2678,  381.8004, 1073.9814,  452.5743]])],\n",
       " [None],\n",
       " [None],\n",
       " [{'ori_shape': (360, 640, 3),\n",
       "   'img_shape': (750, 1333, 3),\n",
       "   'pad_shape': (768, 1344, 3),\n",
       "   'scale_factor': 2.0828125,\n",
       "   'flip': False}],\n",
       " {'assigner': {'type': 'MaxIoUAssigner',\n",
       "   'pos_iou_thr': 0.5,\n",
       "   'neg_iou_thr': 0.4,\n",
       "   'min_pos_iou': 0,\n",
       "   'ignore_iof_thr': -1},\n",
       "  'smoothl1_beta': 0.11,\n",
       "  'gamma': 2.0,\n",
       "  'alpha': 0.25,\n",
       "  'allowed_border': -1,\n",
       "  'pos_weight': -1,\n",
       "  'debug': False})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_overlaps(bboxes1, bboxes2):\n",
    "    \"\"\"Calculate overlap between two set of bboxes.\n",
    "\n",
    "    Args:\n",
    "        bboxes1 (Tensor): shape (m, 4)\n",
    "        bboxes2 (Tensor): shape (n, 4), if is_aligned is ``True``, then m and n\n",
    "            must be equal.\n",
    "\n",
    "    Returns:\n",
    "        ious(Tensor): shape (m, n) \n",
    "    \"\"\"\n",
    "\n",
    "    rows = bboxes1.size(0)\n",
    "    cols = bboxes2.size(0)\n",
    "\n",
    "    if rows * cols == 0:\n",
    "        return bboxes1.new(rows, 1) if is_aligned else bboxes1.new(rows, cols)\n",
    "\n",
    "    lt = torch.max(bboxes1[:, None, :2], bboxes2[:, :2])  # [rows, cols, 2]\n",
    "    rb = torch.min(bboxes1[:, None, 2:], bboxes2[:, 2:])  # [rows, cols, 2]\n",
    "\n",
    "    wh = (rb - lt + 1).clamp(min=0)  # [rows, cols, 2]\n",
    "    overlap = wh[:, :, 0] * wh[:, :, 1]\n",
    "    area1 = (bboxes1[:, 2] - bboxes1[:, 0] + 1) * (\n",
    "        bboxes1[:, 3] - bboxes1[:, 1] + 1)\n",
    "\n",
    "    area2 = (bboxes2[:, 2] - bboxes2[:, 0] + 1) * (\n",
    "        bboxes2[:, 3] - bboxes2[:, 1] + 1)\n",
    "    ious = overlap / (area1[:, None] + area2 - overlap)\n",
    "\n",
    "    return ious\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(bboxes, gt_bboxes, cfg_assigner, gt_bboxes_ignore=None, gt_labels=None):\n",
    "    \"\"\"Assign gt to bboxes.\n",
    "    본 method는 각각의 anchor에 ground truth(이하 gt)를 할당하는 역할을 합니다.\n",
    "    해당 작업이 완료되면 각각의 anchor는 -1, 0, 또는 어떠한 양수값을 갖게 됩니다.\n",
    "    -1은 학습에 사용되지 않는 anchor를 뜻하며\n",
    "    0은 negative sample을 뜻하고\n",
    "    나머지 어떠한 양수값들은 할당된 gt bounding box의 index 번호를 뜻합니다.\n",
    "\n",
    "    위 작업은 아래 정의된 assign_wrt_overlaps 함수에서 아래 순서대로 이뤄집니다.\n",
    "\n",
    "    1. 모든 anchor box에 -1을 할당합니다.\n",
    "    2. 모든 gt들과의 iou가 negative threshold값을 넘지 못하는 anchor box에 0을 할당합니다.\n",
    "       다시 말해 어떠한 gt와도 유의미한 상관관계를 갖지 않는 anchor box를 negative sample로 사용한다는 말 입니다.\n",
    "    3. gt와의 iou가 positive threshold를 넘는 anchor box에 대하여, 가장 가까운(iou가 가장 높은) gt의 index를 부여합니다.\n",
    "    4. 각 gt에 대하여 가장 iou가 높은 anchor box에 해당 gt의 index값을 할당합니다. \n",
    "       3번 과정이 anchor box를 기준으로 이루어졌다면, 본 과정은 gt를 기준으로 이뤄집니다.\n",
    "       만일 어떠한 gt를 기준으로 각 anchor들과의 iou가 모두 positive threshold보다 낮다면 해당 gt에 대해 학습할 positive sample이 없는 상황이 발생합니다.\n",
    "       이럴 때에는 비록 iou가 충분치 않더라도 가장 가까운 anchor를 positive sample로 삼아 학습하게 됩니다.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        bboxes (Tensor): 적절한 label을 할당해줘야 할 anchor box들, shape(n, 4).\n",
    "        gt_bboxes (Tensor): Ground truth box들, shape (k, 4).\n",
    "        gt_bboxes_ignore (Tensor, optional): Ground truth bboxes that are\n",
    "            labelled as `ignored`, e.g., crowd boxes in COCO. 본 예제에서는 고려 대상이 아닙니다.\n",
    "        gt_labels (Tensor, optional): ground truth bbox의 label, shape (k, ).\n",
    "\n",
    "    Returns:\n",
    "        :obj:`AssignResult`: 각 anchor에 적절한 label이 할당된 결과를 담는 객체를 생성하여 return.\n",
    "    \"\"\"\n",
    "\n",
    "    if bboxes.shape[0] == 0 or gt_bboxes.shape[0] == 0:\n",
    "        raise ValueError('No gt or bboxes')\n",
    "    bboxes = bboxes[:, :4]\n",
    "    overlaps = bbox_overlaps(gt_bboxes, bboxes)\n",
    "\n",
    "    assign_result = assign_wrt_overlaps(overlaps, cfg_assigner, gt_labels)\n",
    "    return assign_result\n",
    "\n",
    "\n",
    "def assign_wrt_overlaps(overlaps, cfg_assigner, gt_labels=None):\n",
    "    \"\"\"Assign w.r.t. the overlaps of bboxes with gts.\n",
    "\n",
    "    Args:\n",
    "        overlaps (Tensor): Overlaps between k gt_bboxes and n bboxes,\n",
    "            shape(k, n).\n",
    "        gt_labels (Tensor, optional): Labels of k gt_bboxes, shape (k, ).\n",
    "\n",
    "    Returns:\n",
    "        :obj:`AssignResult`: The assign result.\n",
    "    \"\"\"\n",
    "    if overlaps.numel() == 0:\n",
    "        raise ValueError('No gt or proposals')\n",
    "\n",
    "    num_gts, num_bboxes = overlaps.size(0), overlaps.size(1)\n",
    "\n",
    "    # 1. assign -1 by default\n",
    "    assigned_gt_inds = overlaps.new_full(\n",
    "        (num_bboxes, ), -1, dtype=torch.long)\n",
    "\n",
    "    # for each anchor, which gt best overlaps with it\n",
    "    # for each anchor, the max iou of all gts\n",
    "    max_overlaps, argmax_overlaps = overlaps.max(dim=0)\n",
    "    # for each gt, which anchor best overlaps with it\n",
    "    # for each gt, the max iou of all proposals\n",
    "    gt_max_overlaps, gt_argmax_overlaps = overlaps.max(dim=1)\n",
    "\n",
    "    # 2. assign negative: below\n",
    "    assigned_gt_inds[(max_overlaps >= 0)\n",
    "                     & (max_overlaps < cfg_assigner.neg_iou_thr)] = 0\n",
    "\n",
    "    # 3. assign positive: above positive IoU threshold\n",
    "    pos_inds = max_overlaps >= cfg_assigner.pos_iou_thr\n",
    "    assigned_gt_inds[pos_inds] = argmax_overlaps[pos_inds] + 1\n",
    "\n",
    "    # 4. assign fg: for each gt, proposals with highest IoU\n",
    "    for i in range(num_gts):\n",
    "        if gt_max_overlaps[i] >= cfg_assigner.min_pos_iou:\n",
    "            max_iou_inds = overlaps[i, :] == gt_max_overlaps[i]\n",
    "            assigned_gt_inds[max_iou_inds] = i + 1\n",
    "\n",
    "    if gt_labels is not None:\n",
    "        assigned_labels = assigned_gt_inds.new_zeros((num_bboxes, ))\n",
    "        pos_inds = torch.nonzero(assigned_gt_inds > 0).squeeze()\n",
    "        if pos_inds.numel() > 0:\n",
    "            assigned_labels[pos_inds] = gt_labels[\n",
    "                assigned_gt_inds[pos_inds] - 1]\n",
    "    else:\n",
    "        assigned_labels = None\n",
    "\n",
    "    return AssignResult(\n",
    "        num_gts, assigned_gt_inds, max_overlaps, labels=assigned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0]) tensor([1., 1., 1.,  ..., 1., 1., 1.]) tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) tensor([ 76775,  78278,  78281,  78287,  78290,  78296,  78299,  79790,  79793,\n",
      "         79799,  79802,  79808,  79811,  81302,  81311,  81320, 163115, 163866,\n",
      "        163867, 163868, 163870, 163871, 163876, 163877, 163879, 163880, 163888,\n",
      "        164614, 164615, 164622, 164623, 164624, 164625, 164626, 164627, 164628,\n",
      "        164631, 164632, 164633, 164634, 164635, 164636, 164637, 164640, 164641,\n",
      "        164643, 164644, 165371, 165378, 165379, 165380, 165382, 165383, 165384,\n",
      "        165387, 165388, 165389, 165390, 165391, 165392, 165393, 165396, 165397,\n",
      "        165399, 165400, 166139, 166156, 191200, 191201, 191204, 191384, 191389,\n",
      "        191390, 191392, 191393, 191399, 191402, 191573, 191578, 191579, 191581,\n",
      "        191582, 191588, 191591, 191762, 191767, 191768, 191770, 191771, 191777,\n",
      "        191780, 191955, 191956, 191957, 191958, 191959, 191960, 192137, 192139,\n",
      "        192144, 192145, 192146, 192147, 192148, 192149, 192155, 192157, 192333,\n",
      "        192334, 192336, 192337, 192338, 192526, 192939, 193035, 193038, 193044,\n",
      "        193047, 193137]) tensor([     0,      1,      2,  ..., 193371, 193372, 193373])\n"
     ]
    }
   ],
   "source": [
    "(anchor_list, valid_flag_list, gt_bboxes, gt_bboxes_ignore_list, gt_labels_list, img_metas, train_cfg) = anchor_target_variable\n",
    "\n",
    "flat_anchors = anchor_list[0]\n",
    "valid_flags = valid_flag_list[0]\n",
    "gt_bboxes = gt_bboxes[0]\n",
    "gt_bboxes_ignore = gt_bboxes_ignore_list[0]\n",
    "gt_labels = gt_labels_list[0]\n",
    "img_meta = img_metas[0]\n",
    "cfg = train_cfg\n",
    "\n",
    "\n",
    "inside_flags = anchor_inside_flags(flat_anchors, valid_flags,\n",
    "                                   img_meta['img_shape'][:2],\n",
    "                                   cfg.allowed_border)\n",
    "# assign gt and sample anchors\n",
    "anchors = flat_anchors[inside_flags, :]\n",
    "\n",
    "assign_result = assign(anchors, gt_bboxes, cfg.assigner,\n",
    "                                     gt_bboxes_ignore, gt_labels)\n",
    "bbox_sampler = PseudoSampler()\n",
    "sampling_result = bbox_sampler.sample(assign_result, anchors,\n",
    "                                      gt_bboxes)\n",
    "\n",
    "num_valid_anchors = anchors.shape[0]\n",
    "bbox_targets = torch.zeros_like(anchors)\n",
    "bbox_weights = torch.zeros_like(anchors)\n",
    "labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)\n",
    "label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)\n",
    "\n",
    "pos_inds = sampling_result.pos_inds\n",
    "neg_inds = sampling_result.neg_inds\n",
    "if len(pos_inds) > 0:\n",
    "    pos_bbox_targets = bbox2delta(sampling_result.pos_bboxes,\n",
    "                                  sampling_result.pos_gt_bboxes)\n",
    "    bbox_targets[pos_inds, :] = pos_bbox_targets\n",
    "    bbox_weights[pos_inds, :] = 1.0\n",
    "    if gt_labels is None:\n",
    "        labels[pos_inds] = 1\n",
    "    else:\n",
    "        labels[pos_inds] = gt_labels[sampling_result.pos_assigned_gt_inds]\n",
    "    if cfg.pos_weight <= 0:\n",
    "        label_weights[pos_inds] = 1.0\n",
    "    else:\n",
    "        label_weights[pos_inds] = cfg.pos_weight\n",
    "if len(neg_inds) > 0:\n",
    "    label_weights[neg_inds] = 1.0\n",
    "\n",
    "# map up to original set of anchors\n",
    "\n",
    "num_total_anchors = flat_anchors.size(0)\n",
    "labels = unmap(labels, num_total_anchors, inside_flags)\n",
    "label_weights = unmap(label_weights, num_total_anchors, inside_flags)\n",
    "bbox_targets = unmap(bbox_targets, num_total_anchors, inside_flags)\n",
    "bbox_weights = unmap(bbox_weights, num_total_anchors, inside_flags)\n",
    "\n",
    "print(labels, label_weights, bbox_targets, bbox_weights, pos_inds,\n",
    "        neg_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycon",
   "language": "python",
   "name": "ub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
