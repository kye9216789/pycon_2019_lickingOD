{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from src.anchor.anchor_generator import (gen_base_anchors, get_anchors, \n",
    "                              grid_anchors, meshgrid)\n",
    "from src.anchor.assigner import assign_wrt_overlaps, bbox_overlaps\n",
    "from src.anchor.loss import binary_cross_entropy, smooth_l1_loss\n",
    "from src.anchor.prediction import predict_anchors\n",
    "from src.anchor.transforms import bbox2delta, delta2bbox\n",
    "from src.anchor.visualize import (draw_anchor_gt_overlaps, draw_anchor_samples_on_image, \n",
    "                       draw_base_anchor_on_grid, draw_pos_assigned_bboxes)\n",
    "from src.datasets.loader.build_loader import build_dataloader\n",
    "from src.models.builder import build_backbone, build_neck, build_head\n",
    "from mmcv.runner import obj_from_dict\n",
    "from mmcv.utils.config import Config\n",
    "from src.core import multi_apply, weighted_smoothl1, weighted_sigmoid_focal_loss\n",
    "from src.core.anchor import anchor_target_single, images_to_levels, unmap, anchor_inside_flags, expand_binary_labels\n",
    "\n",
    "from src.core.bbox import assign_and_sample, build_assigner, PseudoSampler, bbox2delta\n",
    "\n",
    "%store -r anchor_target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[ -19.,   -7.,   26.,   14.],\n",
       "          [ -25.,  -10.,   32.,   17.],\n",
       "          [ -32.,  -14.,   39.,   21.],\n",
       "          ...,\n",
       "          [1163.,  342., 1524., 1065.],\n",
       "          [1116.,  248., 1571., 1159.],\n",
       "          [1057.,  129., 1630., 1278.]])],\n",
       " [tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0', dtype=torch.uint8)],\n",
       " [tensor([[ 748.0838,  304.4447,  980.2133,  747.1882],\n",
       "          [ 707.9063,   46.1551, 1026.3268,  670.4366],\n",
       "          [ 982.3378,  359.9517, 1055.0696,  458.0521],\n",
       "          [1012.2678,  381.8004, 1073.9814,  452.5743]])],\n",
       " [None],\n",
       " [None],\n",
       " [{'ori_shape': (360, 640, 3),\n",
       "   'img_shape': (750, 1333, 3),\n",
       "   'pad_shape': (768, 1344, 3),\n",
       "   'scale_factor': 2.0828125,\n",
       "   'flip': False}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0]) tensor([1., 1., 1.,  ..., 1., 1., 1.]) tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) tensor([ 76775,  78278,  78281,  78287,  78290,  78296,  78299,  79790,  79793,\n",
      "         79799,  79802,  79808,  79811,  81302,  81311,  81320, 163115, 163866,\n",
      "        163867, 163868, 163870, 163871, 163876, 163877, 163879, 163880, 163888,\n",
      "        164614, 164615, 164622, 164623, 164624, 164625, 164626, 164627, 164628,\n",
      "        164631, 164632, 164633, 164634, 164635, 164636, 164637, 164640, 164641,\n",
      "        164643, 164644, 165371, 165378, 165379, 165380, 165382, 165383, 165384,\n",
      "        165387, 165388, 165389, 165390, 165391, 165392, 165393, 165396, 165397,\n",
      "        165399, 165400, 166139, 166156, 191200, 191201, 191204, 191384, 191389,\n",
      "        191390, 191392, 191393, 191399, 191402, 191573, 191578, 191579, 191581,\n",
      "        191582, 191588, 191591, 191762, 191767, 191768, 191770, 191771, 191777,\n",
      "        191780, 191955, 191956, 191957, 191958, 191959, 191960, 192137, 192139,\n",
      "        192144, 192145, 192146, 192147, 192148, 192149, 192155, 192157, 192333,\n",
      "        192334, 192336, 192337, 192338, 192526, 192939, 193035, 193038, 193044,\n",
      "        193047, 193137]) tensor([     0,      1,      2,  ..., 193371, 193372, 193373])\n"
     ]
    }
   ],
   "source": [
    "(anchor_list, valid_flag_list, gt_bboxes, gt_bboxes_ignore_list, gt_labels_list, img_metas, train_cfg) = anchor_target_variable\n",
    "\n",
    "flat_anchors = anchor_list[0]\n",
    "valid_flags = valid_flag_list[0]\n",
    "gt_bboxes = gt_bboxes[0]\n",
    "gt_bboxes_ignore = gt_bboxes_ignore_list[0]\n",
    "gt_labels = gt_labels_list[0]\n",
    "img_meta = img_metas[0]\n",
    "cfg = train_cfg\n",
    "label_channels=1\n",
    "\n",
    "inside_flags = anchor_inside_flags(flat_anchors, valid_flags,\n",
    "                                   img_meta['img_shape'][:2],\n",
    "                                   cfg.allowed_border)\n",
    "# assign gt and sample anchors\n",
    "anchors = flat_anchors[inside_flags, :]\n",
    "\n",
    "\n",
    "bbox_assigner = build_assigner(cfg.assigner)\n",
    "assign_result = bbox_assigner.assign(anchors, gt_bboxes,\n",
    "                                     gt_bboxes_ignore, gt_labels)\n",
    "bbox_sampler = PseudoSampler()\n",
    "sampling_result = bbox_sampler.sample(assign_result, anchors,\n",
    "                                      gt_bboxes)\n",
    "\n",
    "num_valid_anchors = anchors.shape[0]\n",
    "bbox_targets = torch.zeros_like(anchors)\n",
    "bbox_weights = torch.zeros_like(anchors)\n",
    "labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)\n",
    "label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)\n",
    "\n",
    "pos_inds = sampling_result.pos_inds\n",
    "neg_inds = sampling_result.neg_inds\n",
    "if len(pos_inds) > 0:\n",
    "    pos_bbox_targets = bbox2delta(sampling_result.pos_bboxes,\n",
    "                                  sampling_result.pos_gt_bboxes)\n",
    "    bbox_targets[pos_inds, :] = pos_bbox_targets\n",
    "    bbox_weights[pos_inds, :] = 1.0\n",
    "    if gt_labels is None:\n",
    "        labels[pos_inds] = 1\n",
    "    else:\n",
    "        labels[pos_inds] = gt_labels[sampling_result.pos_assigned_gt_inds]\n",
    "    if cfg.pos_weight <= 0:\n",
    "        label_weights[pos_inds] = 1.0\n",
    "    else:\n",
    "        label_weights[pos_inds] = cfg.pos_weight\n",
    "if len(neg_inds) > 0:\n",
    "    label_weights[neg_inds] = 1.0\n",
    "\n",
    "# map up to original set of anchors\n",
    "\n",
    "num_total_anchors = flat_anchors.size(0)\n",
    "labels = unmap(labels, num_total_anchors, inside_flags)\n",
    "label_weights = unmap(label_weights, num_total_anchors, inside_flags)\n",
    "if label_channels > 1:\n",
    "    labels, label_weights = expand_binary_labels(\n",
    "        labels, label_weights, label_channels)\n",
    "bbox_targets = unmap(bbox_targets, num_total_anchors, inside_flags)\n",
    "bbox_weights = unmap(bbox_weights, num_total_anchors, inside_flags)\n",
    "\n",
    "print(labels, label_weights, bbox_targets, bbox_weights, pos_inds,\n",
    "        neg_inds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycon",
   "language": "python",
   "name": "ub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
